"""
Example usage of the LangGraph FastAPI integration with Azure OpenAI

This script demonstrates how to use the LangGraph endpoints
Make sure to set your Azure OpenAI credentials in the .env file first!

Required environment variables:
- AZURE_OPENAI_API_KEY
- AZURE_OPENAI_ENDPOINT
- OPENAI_API_VERSION
"""

import asyncio
import httpx

BASE_URL = "http://localhost:8000/api/v1/ai"

async def test_chat_endpoint():
    """Test the simple chat endpoint"""
    print("ğŸ¤– Testing Chat Endpoint...")
    
    async with httpx.AsyncClient() as client:
        # Test greeting
        response = await client.post(
            f"{BASE_URL}/chat",
            json={
                "message": "Hello! How are you?",
                "conversation_id": "test_conversation"
            }
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… Chat Response: {result['response']}")
            print(f"ğŸ“ Workflow State: {result['workflow_state']}")
        else:
            print(f"âŒ Chat failed: {response.status_code} - {response.text}")
        
        # Test question
        response = await client.post(
            f"{BASE_URL}/chat",
            json={
                "message": "What is the capital of France?",
                "conversation_id": "test_conversation"
            }
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… Question Response: {result['response']}")
        else:
            print(f"âŒ Question failed: {response.status_code} - {response.text}")

async def test_task_workflow():
    """Test the complex task workflow"""
    print("\nğŸ”„ Testing Task Workflow...")
    
    async with httpx.AsyncClient(timeout=60.0) as client:
        response = await client.post(
            f"{BASE_URL}/workflow/task",
            json={
                "task": "Plan a weekend trip to Paris",
                "parameters": {
                    "budget": "$1000",
                    "duration": "2 days"
                }
            }
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… Task Result: {result['result'][:200]}...")
            print(f"ğŸ“Š Status: {result['status']}")
            print(f"ğŸ“‹ Steps Completed: {len(result['steps'])}")
            
            for i, step in enumerate(result['steps'], 1):
                print(f"   Step {i}: {step['description']}")
        else:
            print(f"âŒ Task workflow failed: {response.status_code} - {response.text}")

async def test_conversation_history():
    """Test conversation history endpoint"""
    print("\nğŸ“š Testing Conversation History...")
    
    async with httpx.AsyncClient() as client:
        response = await client.get(f"{BASE_URL}/conversations/test_conversation")
        
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… Found {len(result['messages'])} messages in conversation")
            for msg in result['messages'][-2:]:  # Show last 2 messages
                print(f"   {msg['role']}: {msg['content'][:100]}...")
        else:
            print(f"âŒ History failed: {response.status_code} - {response.text}")

async def test_health_check():
    """Test the health check endpoint"""
    print("\nğŸ¥ Testing Health Check...")
    
    async with httpx.AsyncClient() as client:
        response = await client.get(f"{BASE_URL}/health")
        
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… Service Status: {result['status']}")
            print(f"ğŸ”— LLM Connected: {result['llm_connected']}")
            print(f"ğŸ’¬ Active Conversations: {result['active_conversations']}")
        else:
            print(f"âŒ Health check failed: {response.status_code} - {response.text}")

async def main():
    """Run all tests"""
    print("ğŸš€ Starting LangGraph FastAPI Integration Tests")
    print("=" * 50)
    
    try:
        await test_health_check()
        await test_chat_endpoint()
        await test_task_workflow()
        await test_conversation_history()
        
        print("\n" + "=" * 50)
        print("âœ… All tests completed!")
        print("ğŸ’¡ Try these endpoints in your browser:")
        print("   ğŸ“– API Docs: http://localhost:8000/docs")
        print(f"   ğŸ¤– Chat: POST {BASE_URL}/chat")
        print(f"   ğŸ”„ Workflow: POST {BASE_URL}/workflow/task")
        
    except httpx.ConnectError:
        print("âŒ Could not connect to FastAPI server.")
        print("ğŸ’¡ Make sure the server is running: uvicorn app.main:app --reload")
    except Exception as e:
        print(f"âŒ Error running tests: {str(e)}")

if __name__ == "__main__":
    asyncio.run(main())